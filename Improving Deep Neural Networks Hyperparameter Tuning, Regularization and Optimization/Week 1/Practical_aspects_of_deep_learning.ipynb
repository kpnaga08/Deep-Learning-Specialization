{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "\n",
    "If you have 20,000,000 examples, how would you split the train/dev/test set? Choose the best option.\n",
    "\n",
    "- [ ] 60% train. 20% dev. 20% test.\n",
    "\n",
    "- **<font color='green'>[x] 99% train. 0.5% dev. 0.5% test.</font>**\n",
    "\n",
    "  **<font color='magenta'> Given the size of the dataset, 0.5% of the samples are enough to get a good estimate of how well the model is doing..</font>**\n",
    "\n",
    "- [ ] 90% train. 5% dev. 5% test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "When designing a neural network to detect if a house cat is present in the picture, 500,000 pictures of cats were taken by their owners. These are used to make the training, dev and test sets. It is decided that to increase the size of the test set, 10,000 new images of cats taken from security cameras are going to be used in the test set. Which of the following is true?\n",
    "\n",
    "- [ ] This will increase the bias of the model so the new images shouldn't be used.\n",
    "\n",
    "- **<font color='green'>[x]This will be harmful to the project since now dev and test sets have different distributions</font>**\n",
    "  \n",
    "  **<font color='magenta'>The quality and type of images are quite different thus we can't consider that the dev and the test sets came from the same distribution.</font>**\n",
    "\n",
    "- This will reduce the bias of the model and help improve it.\n",
    "\n",
    "  **<font color='red'> This won't have a real effect on the bias of the model but will hinder the way we are measuring the performance..</font>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "A model developed for a project is presenting high bias. One of the sponsors of the project offers some resources that might help reduce the bias. Which of the following additional resources has a better chance to help reduce the bias?\n",
    "\n",
    "- **<font color='green'>[x] Give access to more computational resources like GPUs.</font>**\n",
    "\n",
    "- Gather more data for the project\n",
    "\n",
    "- Use different sources to gather data and better test the model\n",
    "\n",
    "  **<font color='red'> More test data won't help reduce the bias.</font>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "You are working on an automated check-out kiosk for a supermarket and are building a classifier for apples, bananas, and oranges. Suppose your classifier obtains a training set error of 19% and a dev set error of 21%. Which of the following are promising things to try to improve your classifier? (Check all that apply, suppose the human error is approximately 0%)\n",
    "\n",
    "- Get more training data\n",
    "\n",
    "  **<font color='red'> This won't help to reduce the high bias of the model; it is better to address that first before moving to reduce a high variance.</font>**\n",
    "\n",
    "-  **<font color='green'>[x] Use a bigger network.</font>**\n",
    "\n",
    "   **<font color='magenta'> This can be helpful to reduce the bias of the model, and then we can start trying to reduce the high variance if this happens.</font>**\n",
    "\n",
    "- Increase the regularization parameter lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Which of the following are regularization techniques?\n",
    "\n",
    "- **<font color='green'>[x] Dropout</font>**\n",
    "\n",
    "- **<font color='green'>[x] Weight decay</font>**\n",
    "\n",
    "- Increase the number of layers of the network\n",
    "\n",
    "- Gradient checking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "To reduce high variance, the regularization hyperparameter lambda must be increased. True/False?\n",
    "\n",
    "- True\n",
    "\n",
    "- **<font color='green'>[x] False</font>**\n",
    "\n",
    "  **<font color='magenta'>  By increasing the regularization parameter the magnitude of the weight parameters is reduced. This helps reduce the variance.</font>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "\n",
    "Which of the following are true about dropout?\n",
    "\n",
    "- In practice, it eliminates units of each layer with a probability of keep_prob\n",
    "\n",
    "  **<font color='red'> The dropout is a regularization technique and thus helps to reduce the overfit.</font>**\n",
    "\n",
    "- **<font color='green'> [x] In practice, it eliminates units of each layer with a probability of 1-keep_prob.</font>**\n",
    "\n",
    "  **<font color='magenta'>  The dropout is a regularization technique and thus helps to reduce the overfit.</font>**\n",
    "\n",
    "- It helps to reduce the bias of a model\n",
    "\n",
    "- **<font color='green'>[x] It helps to reduce the variance of a model</font>**\n",
    "\n",
    "  **<font color='magenta'>  The dropout is a regularization technique and thus helps to reduce the variance.</font>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "\n",
    "During training a deep neural network that uses the tanh activation function, the value of the gradients is practically zero. Which of the following is most likely to help the vanishing gradient problem?\n",
    "\n",
    "- Use a larger regularization parameter\n",
    "\n",
    "- **<font color='green'> [x] Use Xavier initialization</font>**\n",
    "\n",
    "  **<font color='magenta'>  A careful initialization can help reduce the vanishing gradient problem.</font>**\n",
    "\n",
    "- Increase the number of cycles during the training\n",
    "\n",
    "- Increase the number of layers of the network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "\n",
    "Which of the following actions increase the regularization of a model? (Check all that apply)\n",
    "\n",
    "- **<font color='green'> [x] Make use of data augmentation</font>**\n",
    "\n",
    "  **<font color='magenta'> Data augmentation has a way to generate \"new\" data at a relatively low cost. Thus making use of data augmentation can reduce the variance.</font>**\n",
    "\n",
    "- Decrease the value of the hyperparameter lambda\n",
    "\n",
    "- **<font color='green'> [x] Decrease the value of keep_prob in dropout</font>**\n",
    "\n",
    "- Increase the value of keep_prob in dropout\n",
    "\n",
    "  **<font color='red'> When increasing the keep_prob value, the probability that a node gets discarded during training is less, thus reducing the regularization effect.</font>**\n",
    "\n",
    "- Use Xavier initialization\n",
    "\n",
    "  **<font color='red'> Xavier doesn't have any effect on reducing the variance of the model, thus it's not a regularization technique.</font>**\n",
    "\n",
    "- **<font color='green'> [x] Increase the value of hyperparameter lambda</font>**\n",
    "\n",
    "  **<font color='magenta'> When increasing the hyperparameter lambda we increase the effect of the $L_{2}$ penalization.</font>**\n",
    "\n",
    "- Normalizing the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "\n",
    "Which of the following is the correct expression to normalize the input $\\mathbf{x}x$?\n",
    "\n",
    "- $ x = \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}$\n",
    "\n",
    "-  $ x = \\frac{1}{m} \\sum_{i=1}^{m} (x^{(i)})^{2}$\n",
    "\n",
    "-  $ x = \\fac{x}{\\delta}\n",
    "\n",
    "- **<font color='green'> [x] $\\mathbf{x = \\frac{x - \\mu}{\\delta}}$</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11 \n",
    "\n",
    "If you have 10,000,000 examples, how would you split the train/dev/test set?\n",
    "\n",
    "- [ ] 60% train. 20% dev. 20% test.\n",
    "\n",
    "- **<font color='green'>[x] 98% train. 1% dev. 1% test.</font>**\n",
    "\n",
    "- [ ] 33% train. 33% dev. 33% test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 12 \n",
    "\n",
    "In a personal experiment, an M.L. student decides to not use a test set, only train-dev sets. In this case which of the following is true?\n",
    "\n",
    "- [ ] Not having a test set is unacceptable under any circumstance.\n",
    "\n",
    "- [ ] He won't be able to measure the variance of the model\n",
    "\n",
    "- **<font color='green'>[x] He might be overfitting to the dev set</font>**\n",
    "\n",
    "  **<font color='magenta'>  Although not recommended, if a more accurate measure of the performance is not necessary it is ok to not use a test set. However, this might cause an overfit to the dev set.</font>**\n",
    "\n",
    "- [ ] He won't be able to measure the bias of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 13 \n",
    "\n",
    "If your Neural Network model seems to have high variance, what of the following would be promising things to try?\n",
    "\n",
    "- [ ] Make the Neural Network deeper\n",
    "\n",
    "- **<font color='green'>[x] Get more training data</font>**\n",
    "\n",
    "- [ ] Increase the number of units in each hidden layer\n",
    "\n",
    "- **<font color='green'>[x] Add regularization</font>**\n",
    "\n",
    "- [ ] Get more test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 14 \n",
    "\n",
    "The regularization hyperparameter must be set to zero during testing to avoid getting random results. True/False?\n",
    "\n",
    "- **<font color='green'>[x] False</font>**\n",
    "\n",
    "  **<font color='magenta'> The regularization parameter affects how the weights change during training, this means during backpropagation. It has no effect during the forward propagation that is when predictions for the test are made.</font>**\n",
    "\n",
    "- [ ] True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 15 \n",
    "\n",
    "Increasing the parameter keep_prob from (say) 0.5 to 0.6 will likely cause the following: (Check the two that apply)\n",
    "\n",
    "- Increasing the regularization effect\n",
    "\n",
    "- **<font color='green'>[x] Reducing the regularization effect</font>**\n",
    "\n",
    "- [ ] Causing the neural network to end up with a higher training set error\n",
    "\n",
    "- **<font color='green'>[x] Causing the neural network to end up with a lower training set error</font>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 16 \n",
    "\n",
    "Why do we normalize the inputs $x$ ?\n",
    "\n",
    "- It makes the parameter initialization faster\n",
    "\n",
    "- It makes it easier to visualize the data\n",
    "\n",
    "- Normalization is another word for regularization -- it help to reduce variance\n",
    "\n",
    "- **<font color='green'>[x] It makes the cost function faster to optimize</font>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 17\n",
    "\n",
    "Working on a model to classify bananas and oranges your classifier gets a training set error of 0.1% and a dev set error of 11%. Which of the following two are true?\n",
    "\n",
    "- The model is overfitting the dev set\n",
    "\n",
    "- **<font color='green'>[x]The model has a high variance</font>**\n",
    "\n",
    "- **<font color='green'>[x]The model is overfitting the train set</font>**\n",
    "\n",
    "- The model has a very high bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 18\n",
    "\n",
    "The dev and test set should:\n",
    "\n",
    "- **<font color='green'>[x]Come from the same distribution</font>**\n",
    "\n",
    "- Come from differen distribution\n",
    "\n",
    "- Be identical to each other (same $(x,y)$ pairs)\n",
    "\n",
    "- Have the same number of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 19\n",
    "\n",
    "Suppose that a model uses, as one feature, the total number of kilometers walked by a person during a year, and another feature is the height of the person in meters. What is the most likely effect of normalization of the input data?\n",
    "\n",
    "- It will make the data easier to visualize\n",
    "\n",
    "- It won't have any positive or negative effects\n",
    "\n",
    "- **<font color='green'>[x] It will make the training faster</font>**\n",
    "\n",
    "  **<font color='magenta'>Since the difference between the ranges of the features is very different, this will likely cause the process of gradient descent to oscillate, making the optimization process longer.</font>**\n",
    "\n",
    "- It will increase the variance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
